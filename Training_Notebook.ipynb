{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, AveragePooling2D, Flatten\n",
    "from keras.layers import Input, concatenate, Conv2D, BatchNormalization, Activation\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data_package01/sensor-01/scc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['SCC_below_56', 'SCC_56-132', 'SCC_above_132']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unq_id(images_list):\n",
    "    id_list = []\n",
    "    for image_name in images_list:\n",
    "        id_list.append(image_name[:-6])    \n",
    "    unq_id_list = list(set(id_list))\n",
    "    return unq_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_data_dict = {}\n",
    "class_map = {}\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print class_name\n",
    "    class_map[i] = class_name\n",
    "    images_list = os.listdir(os.path.join(data_path, class_name))\n",
    "    unq_id_list = get_unq_id(images_list)\n",
    "    unq_data_dict[i] = unq_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified splitting into Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.2 #fraction of data to be used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_train_data_dict = {}\n",
    "unq_val_data_dict = {}\n",
    "## Since we have 5 images from same sample. It is not good to have some images in \n",
    "## train and other in val for the sample. So train and val split is done based on sample ID.\n",
    "for class_number, unq_id_list in unq_data_dict.items():\n",
    "    total_ids = len(unq_id_list)\n",
    "    num_train_ids = int((1-val_fraction)*total_ids)\n",
    "    num_val_ids = total_ids - num_train_ids\n",
    "    \n",
    "    train_id_list = random.sample(unq_id_list, num_train_ids)\n",
    "    val_id_list = []\n",
    "    for unq_id in unq_id_list:\n",
    "        if unq_id not in train_id_list:\n",
    "            val_id_list.append(unq_id)\n",
    "    \n",
    "    unq_train_data_dict[class_number] = train_id_list\n",
    "    unq_val_data_dict[class_number] = val_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "valX = []\n",
    "trainY = []\n",
    "valY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Images are resized to 640x240.\n",
    "\n",
    "for class_number, unq_id_list in unq_train_data_dict.items():\n",
    "    class_name = class_map[class_number]\n",
    "    for unq_id in unq_id_list:\n",
    "        for i in range(5):\n",
    "            img_name = unq_id + \"_\"+ str(i)+ \".png\"\n",
    "            \n",
    "            img_path = os.path.join(data_path, class_name,img_name)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(size=(640,240))\n",
    "            img_array = np.asarray(img)\n",
    "            \n",
    "            trainX.append(img_array)\n",
    "            trainY.append(class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle training data\n",
    "c = list(zip(trainX, trainY))\n",
    "random.shuffle(c)\n",
    "trainX, trainY = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_number, unq_id_list in unq_val_data_dict.items():\n",
    "    class_name = class_map[class_number]\n",
    "    for unq_id in unq_id_list:\n",
    "        for i in range(5):\n",
    "            img_name = unq_id + \"_\"+ str(i)+ \".png\"\n",
    "            \n",
    "            img_path = os.path.join(data_path, class_name,img_name)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(size=(640,240))\n",
    "            img_array = np.asarray(img)\n",
    "            \n",
    "            valX.append(img_array)\n",
    "            valY.append(class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute class weights to account for label imbalance\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(trainY),\n",
    "                                                 trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=3)\n",
    "valY = to_categorical(valY, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.asarray(trainX)\n",
    "valX = np.asarray(valX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in numpy array for later use\n",
    "np.savez(\"train_val_data_v3.npz\", trainX, trainY, valX, valY, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data if it is already saved\n",
    "\n",
    "# data = np.load(\"train_val_data_v3.npz\")\n",
    "# trainX = data[\"arr_0\"]\n",
    "# trainY = data[\"arr_1\"]\n",
    "# valX = data[\"arr_2\"]\n",
    "# valY = data[\"arr_3\"]\n",
    "# class_weights = data[\"arr_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess image data : subtract mean and scale std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We train a model with two inputs. One for processing LED part of the images and other for processing laser part.\n",
    "## hence we separate each image into two parts and then preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_blue = trainX[:,:,:320,:]\n",
    "trainX_red = trainX[:,:,320:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX_blue = valX[:,:,:320,:]\n",
    "valX_red = valX[:,:,320:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_data(X):\n",
    "    # subtract channel mean and divide by standard deviation\n",
    "    X = X.astype(float)\n",
    "    mean_X = np.mean(X, axis = (0,1,2))\n",
    "    X -= mean_X\n",
    "    std_X = np.std(X, axis = (0,1,2))\n",
    "    X /= std_X\n",
    "    return X, mean_X, std_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_val_data(X, mean_X, std_X):\n",
    "    # preprocess validation data using mean and std from train data\n",
    "    X = X.astype(float)\n",
    "    X -= mean_X\n",
    "    X /= std_X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_blue_normalized, mean_blue, std_blue = preprocess_train_data(trainX_blue)\n",
    "trainX_red_normalized, mean_red, std_red = preprocess_train_data(trainX_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX_blue = preprocess_val_data(valX_blue, mean_blue, std_blue)\n",
    "valX_red = preprocess_val_data(valX_red, mean_red, std_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight l2 regularization to avoid overfitting of the model\n",
    "l2_reg = regularizers.l2(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given only couple thousand images for training, a very shallow model with few thousand parameters was trained.\n",
    "# The model has two parallel streams that have identical architecture for processing red and blue part of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(240,320,3), name='input1')\n",
    "input_2 = Input(shape=(240,320,3), name='input2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Conv2D(4, kernel_size=(3,3), kernel_regularizer=l2_reg)(input_1)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x= Conv2D(4, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "output_1 = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Conv2D(4, kernel_size=(3,3), kernel_regularizer=l2_reg)(input_2)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x= Conv2D(4, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x= Conv2D(8, kernel_size=(3,3), kernel_regularizer=l2_reg)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "output_2 = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine outputs from two streams\n",
    "\n",
    "x = concatenate([output_1, output_2])\n",
    "output = Dense(3, activation='softmax', kernel_regularizer=l2_reg)(x) # 3 class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_1, input_2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             (None, 240, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             (None, 240, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 238, 318, 4)  112         input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 238, 318, 4)  112         input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 238, 318, 4)  16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 238, 318, 4)  16          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 238, 318, 4)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 238, 318, 4)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 236, 316, 4)  148         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 236, 316, 4)  148         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 236, 316, 4)  16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 236, 316, 4)  16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 236, 316, 4)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 236, 316, 4)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 118, 158, 4)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 118, 158, 4)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 116, 156, 8)  296         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 116, 156, 8)  296         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 116, 156, 8)  32          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 116, 156, 8)  32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 116, 156, 8)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 116, 156, 8)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 58, 78, 8)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 58, 78, 8)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 76, 8)    584         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 76, 8)    584         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 76, 8)    32          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 76, 8)    32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 76, 8)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 76, 8)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 28, 38, 8)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 28, 38, 8)    0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 26, 36, 8)    584         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 26, 36, 8)    584         average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 26, 36, 8)    32          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 26, 36, 8)    32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 26, 36, 8)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 26, 36, 8)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 13, 18, 8)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 13, 18, 8)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1872)         0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1872)         0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3744)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            11235       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,939\n",
      "Trainable params: 14,811\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss function is used because it is a multiclass model.\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks to checkpoint models, save logs and early stopping to monitor val loss\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\"exp4/weights.{epoch:02d}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "csvlogger_callback = keras.callbacks.CSVLogger(\"exp4/logs.csv\", separator=',', append=False)\n",
    "earlystopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='auto', baseline=None)\n",
    "\n",
    "callbacks = [checkpoint_callback, csvlogger_callback, earlystopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 490 samples\n",
      "Epoch 1/1000\n",
      "1920/1920 [==============================] - 60s 31ms/step - loss: 5.2683 - acc: 0.5755 - val_loss: 3.9790 - val_acc: 0.5673\n",
      "Epoch 2/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 3.2885 - acc: 0.5719 - val_loss: 2.8429 - val_acc: 0.5531\n",
      "Epoch 3/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 2.4571 - acc: 0.5849 - val_loss: 2.2653 - val_acc: 0.5449\n",
      "Epoch 4/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 2.0291 - acc: 0.5797 - val_loss: 1.9732 - val_acc: 0.5612\n",
      "Epoch 5/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.7565 - acc: 0.5865 - val_loss: 1.8153 - val_acc: 0.5673\n",
      "Epoch 6/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.5855 - acc: 0.5938 - val_loss: 1.7580 - val_acc: 0.5673\n",
      "Epoch 7/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.4678 - acc: 0.6026 - val_loss: 1.5447 - val_acc: 0.5286\n",
      "Epoch 8/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.3741 - acc: 0.5984 - val_loss: 1.6120 - val_acc: 0.5449\n",
      "Epoch 9/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.3127 - acc: 0.6083 - val_loss: 1.5338 - val_acc: 0.4796\n",
      "Epoch 10/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.2637 - acc: 0.6089 - val_loss: 1.5808 - val_acc: 0.4510\n",
      "Epoch 11/1000\n",
      "1920/1920 [==============================] - 57s 29ms/step - loss: 1.2175 - acc: 0.6146 - val_loss: 1.4673 - val_acc: 0.5327\n",
      "Epoch 12/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.1829 - acc: 0.6219 - val_loss: 1.3685 - val_acc: 0.4429\n",
      "Epoch 13/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.1559 - acc: 0.6156 - val_loss: 1.4373 - val_acc: 0.5265\n",
      "Epoch 14/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.1334 - acc: 0.6214 - val_loss: 1.3954 - val_acc: 0.4592\n",
      "Epoch 15/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.1107 - acc: 0.6203 - val_loss: 1.5102 - val_acc: 0.4837\n",
      "Epoch 16/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.1120 - acc: 0.6271 - val_loss: 1.4068 - val_acc: 0.4265\n",
      "Epoch 17/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.0844 - acc: 0.6250 - val_loss: 1.4603 - val_acc: 0.4327\n",
      "Epoch 18/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.0746 - acc: 0.6307 - val_loss: 1.3733 - val_acc: 0.3571\n",
      "Epoch 19/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 1.0547 - acc: 0.6333 - val_loss: 1.4691 - val_acc: 0.4122\n",
      "Epoch 20/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.0369 - acc: 0.6422 - val_loss: 1.4342 - val_acc: 0.4653\n",
      "Epoch 21/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.0277 - acc: 0.6401 - val_loss: 1.4740 - val_acc: 0.4347\n",
      "Epoch 22/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.0137 - acc: 0.6391 - val_loss: 1.4523 - val_acc: 0.4367\n",
      "Epoch 23/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 1.0019 - acc: 0.6469 - val_loss: 1.5211 - val_acc: 0.4061\n",
      "Epoch 24/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9998 - acc: 0.6490 - val_loss: 1.3882 - val_acc: 0.4347\n",
      "Epoch 25/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9911 - acc: 0.6469 - val_loss: 1.5239 - val_acc: 0.3918\n",
      "Epoch 26/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9787 - acc: 0.6578 - val_loss: 1.4153 - val_acc: 0.3878\n",
      "Epoch 27/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.9747 - acc: 0.6589 - val_loss: 1.4299 - val_acc: 0.4245\n",
      "Epoch 28/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9736 - acc: 0.6536 - val_loss: 1.5942 - val_acc: 0.4367\n",
      "Epoch 29/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9650 - acc: 0.6688 - val_loss: 1.5251 - val_acc: 0.4265\n",
      "Epoch 30/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.9440 - acc: 0.6599 - val_loss: 1.5537 - val_acc: 0.4122\n",
      "Epoch 31/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.9491 - acc: 0.6656 - val_loss: 1.3646 - val_acc: 0.4347\n",
      "Epoch 32/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.9444 - acc: 0.6661 - val_loss: 1.4936 - val_acc: 0.4735\n",
      "Epoch 33/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9343 - acc: 0.6729 - val_loss: 1.7852 - val_acc: 0.4265\n",
      "Epoch 34/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9299 - acc: 0.6833 - val_loss: 1.4341 - val_acc: 0.4633\n",
      "Epoch 35/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9242 - acc: 0.6781 - val_loss: 1.5805 - val_acc: 0.4469\n",
      "Epoch 36/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9236 - acc: 0.6813 - val_loss: 1.4491 - val_acc: 0.4102\n",
      "Epoch 37/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.9130 - acc: 0.6943 - val_loss: 1.4574 - val_acc: 0.4633\n",
      "Epoch 38/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9166 - acc: 0.6849 - val_loss: 1.6751 - val_acc: 0.4204\n",
      "Epoch 39/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.9050 - acc: 0.6922 - val_loss: 1.5449 - val_acc: 0.4143\n",
      "Epoch 40/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8949 - acc: 0.6953 - val_loss: 1.7588 - val_acc: 0.4510\n",
      "Epoch 41/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8941 - acc: 0.6958 - val_loss: 1.5023 - val_acc: 0.4612\n",
      "Epoch 42/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8914 - acc: 0.7036 - val_loss: 1.4748 - val_acc: 0.4694\n",
      "Epoch 43/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8907 - acc: 0.6917 - val_loss: 1.7551 - val_acc: 0.4163\n",
      "Epoch 44/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8814 - acc: 0.7010 - val_loss: 1.6201 - val_acc: 0.4245\n",
      "Epoch 45/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8743 - acc: 0.7057 - val_loss: 1.7601 - val_acc: 0.4510\n",
      "Epoch 46/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8758 - acc: 0.7057 - val_loss: 1.7597 - val_acc: 0.4184\n",
      "Epoch 47/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8687 - acc: 0.7016 - val_loss: 1.5782 - val_acc: 0.4061\n",
      "Epoch 48/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8617 - acc: 0.7135 - val_loss: 1.6889 - val_acc: 0.4204\n",
      "Epoch 49/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8655 - acc: 0.7036 - val_loss: 1.6427 - val_acc: 0.4531\n",
      "Epoch 50/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8574 - acc: 0.7068 - val_loss: 1.4782 - val_acc: 0.4592\n",
      "Epoch 51/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8505 - acc: 0.7094 - val_loss: 1.6809 - val_acc: 0.4633\n",
      "Epoch 52/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8444 - acc: 0.7120 - val_loss: 1.6722 - val_acc: 0.4408\n",
      "Epoch 53/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8450 - acc: 0.7234 - val_loss: 1.7634 - val_acc: 0.4184\n",
      "Epoch 54/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8377 - acc: 0.7276 - val_loss: 1.5266 - val_acc: 0.4469\n",
      "Epoch 55/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.8346 - acc: 0.7297 - val_loss: 1.7568 - val_acc: 0.4082\n",
      "Epoch 56/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.8227 - acc: 0.7344 - val_loss: 1.7565 - val_acc: 0.4531\n",
      "Epoch 57/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.8319 - acc: 0.7266 - val_loss: 1.7671 - val_acc: 0.4449\n",
      "Epoch 58/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.8236 - acc: 0.7271 - val_loss: 1.7073 - val_acc: 0.4408\n",
      "Epoch 59/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.8216 - acc: 0.7328 - val_loss: 1.7552 - val_acc: 0.4633\n",
      "Epoch 60/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.8198 - acc: 0.7313 - val_loss: 1.7170 - val_acc: 0.4347\n",
      "Epoch 61/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8075 - acc: 0.7328 - val_loss: 1.9495 - val_acc: 0.4306\n",
      "Epoch 62/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8104 - acc: 0.7370 - val_loss: 1.7893 - val_acc: 0.4367\n",
      "Epoch 63/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8078 - acc: 0.7380 - val_loss: 1.7608 - val_acc: 0.4347\n",
      "Epoch 64/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8086 - acc: 0.7349 - val_loss: 1.9971 - val_acc: 0.4204\n",
      "Epoch 65/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.8023 - acc: 0.7318 - val_loss: 1.7223 - val_acc: 0.4265\n",
      "Epoch 66/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.7944 - acc: 0.7406 - val_loss: 1.7358 - val_acc: 0.4469\n",
      "Epoch 67/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7902 - acc: 0.7385 - val_loss: 1.9587 - val_acc: 0.4490\n",
      "Epoch 68/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7888 - acc: 0.7438 - val_loss: 1.7639 - val_acc: 0.4306\n",
      "Epoch 69/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.7947 - acc: 0.7464 - val_loss: 1.7733 - val_acc: 0.4653\n",
      "Epoch 70/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7831 - acc: 0.7474 - val_loss: 1.8052 - val_acc: 0.4612\n",
      "Epoch 71/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7766 - acc: 0.7568 - val_loss: 1.7141 - val_acc: 0.4510\n",
      "Epoch 72/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.7744 - acc: 0.7547 - val_loss: 1.6782 - val_acc: 0.4122\n",
      "Epoch 73/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7764 - acc: 0.7490 - val_loss: 1.9241 - val_acc: 0.4163\n",
      "Epoch 74/1000\n",
      "1920/1920 [==============================] - 55s 29ms/step - loss: 0.7694 - acc: 0.7682 - val_loss: 1.7488 - val_acc: 0.4265\n",
      "Epoch 75/1000\n",
      "1920/1920 [==============================] - 56s 29ms/step - loss: 0.7594 - acc: 0.7604 - val_loss: 1.8738 - val_acc: 0.4510\n",
      "Epoch 76/1000\n",
      "1920/1920 [==============================] - 57s 30ms/step - loss: 0.7551 - acc: 0.7589 - val_loss: 2.0071 - val_acc: 0.4163\n",
      "Epoch 77/1000\n",
      "  71/1920 [>.............................] - ETA: 49s - loss: 0.7493 - acc: 0.8028"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4e1f95180f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainX_blue_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX_red_normalized\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalX_blue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalX_red\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[trainX_blue_normalized, trainX_red_normalized], y=trainY, batch_size=1, epochs=1000, verbose=1, validation_data=([valX_blue, valX_red], valY), callbacks=callbacks, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Logs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_epoch : 18\n"
     ]
    }
   ],
   "source": [
    "# Read logs file to look at loss curves and get best epoch\n",
    "\n",
    "with open(\"exp4/logs.csv\",'r') as f:\n",
    "    data_iter = csv.reader(f,delimiter = ',')\n",
    "    data = [data for data in data_iter]\n",
    "    \n",
    "train_loss = [float(line[2]) for line in data[1:]]\n",
    "val_loss = [float(line[3]) for line in data[1:]]\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_loss)\n",
    "plt.show()\n",
    "\n",
    "print \"best_epoch : {}\".format(np.argmin(val_loss)+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
